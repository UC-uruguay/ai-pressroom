name: Daily Podcast Generation

on:
  # Run daily at 6:00 AM UTC (3:00 PM JST)
  schedule:
    - cron: '0 6 * * *'

  # Allow manual trigger
  workflow_dispatch:
    inputs:
      date:
        description: 'Episode date (YYYY-MM-DD), leave empty for today'
        required: false
        type: string

jobs:
  generate-podcast:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Verify ffmpeg installation
        run: ffmpeg -version

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create data directories
        run: |
          mkdir -p data/{news_raw,news_clean,transcripts,audio_stems,episodes,metadata}

      - name: Setup configuration
        run: |
          cp configs/settings.example.yaml configs/settings.yaml
          # Note: Edit configs/settings.yaml in CI if needed for custom sources

      - name: Run daily podcast generation
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          ELEVENLABS_API_KEY: ${{ secrets.ELEVENLABS_API_KEY }}
          S3_ENDPOINT: ${{ secrets.S3_ENDPOINT }}
          S3_ACCESS_KEY: ${{ secrets.S3_ACCESS_KEY }}
          S3_SECRET_KEY: ${{ secrets.S3_SECRET_KEY }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
        run: |
          if [ -n "${{ github.event.inputs.date }}" ]; then
            python -m src.cli run-daily --date "${{ github.event.inputs.date }}"
          else
            python -m src.cli run-daily
          fi

      - name: Upload episode artifacts
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: episode-${{ github.run_number }}
          path: |
            data/episodes/*.mp3
            data/podcast.xml
            data/metadata/*.json
          retention-days: 30

      - name: Upload to S3 (if configured)
        if: success() && vars.ENABLE_S3_UPLOAD == 'true'
        run: |
          # This step would upload the generated files to S3/R2
          # Implement based on your storage backend
          echo "S3 upload would happen here"

      # Optional: Commit and push RSS feed back to repo
      - name: Commit RSS feed
        if: success() && vars.COMMIT_RSS == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/podcast.xml data/metadata/
          git diff --quiet && git diff --staged --quiet || git commit -m "Update podcast RSS feed - $(date +'%Y-%m-%d')"
          git push

  # Optional: Test job that runs on PR
  test:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          sudo apt-get update && sudo apt-get install -y ffmpeg
          pip install -r requirements.txt

      - name: Run tests
        run: |
          pytest tests/ -v

      - name: Validate configuration
        run: |
          cp configs/settings.example.yaml configs/settings.yaml
          python -m src.cli validate-config
